				----------- [ TRANSACTION ] ----------

-- transaction the storing of the data in the log file is called the transaction
-- like when @insert into tableName values(,,)
-- implicit transaction -- automatically done by sql server in each command and save all commands automatically save it in log file
	-- beging transaction	and start to insert into the table and check if it will transact without any errors in the insertion 
	-- if the transaction done it will out [ commit ] if not it will out [ rollback ] 
	-- so any transactions only have two cases, [ commit - rollback ]
	
-- if server down before implicit transaction not finished -- it will rollback automatically @@ when electricity down


-- exiplict transaction 
	@
		begin tranaction			-- we could write tran instead of writing the full name
			insert into [].[] values (,,)	
			commit		-- it will add the values to the table 
			-- rollback	-- in this case it will not add the values to the table but will show message completed successfully
			
	@

-- backups have three types
	-- fullbackup			-- backup full database from creation  		-- mdf/ndf	-- bigger volume of all 					-- speedest one of all 
	-- deferential backup		-- backup from latest full backup		-- mdf/ndf	-- smaller that fullbackup and bigger than transactional	-- slowest one of all
	-- transactional log backup	-- backup from latest backup of any type	-- LOG FILE 	-- after taking the backups here it empty log file		-- more speed than full
	
	-- if I want to automatically backup data we use sql agent (sql adminstration)

	-- the meta data contains times of modifying		-- [ transactional log backup ] saves those meta data

	-- when restoring we may have to restart the sql servive from windows servieces $$ make it take lower time restoreing

	-- you cat restore the full without the differential but You can't do the opposite (defferential without full)

	-- all types could save on the same file You will see it 

-- indexing 
	-- any table without brimary key called ( HEAP table ) sorted as inserted
	-- seqeuntial search | row scanning that in case we don't have a primary key 

	-- but if we have a primary the data will be ordered depend on primary key for ex if we have data and we insert a record it will be located on the table depend on the primary key

	-- clustered index order the data by the primary key by default	
	-- index will convert the scanning from table scanning to database page scanning [ HIGHER  PERFORMANCE ]
	-- but if I need to sarch with another column not primary key like name or whatever then we can use nonclustered index
	-- so we could add cluster index only one allowed and nonclustered index more than one to enhance the performance of select 

	-- so after adding index to a table it creates a page in the memory like a tree that uses binary search
	-- index affected by dml transaction so it will affect the performance and exhaust the engine, wo we don't use index 
	-- $$ tunning advisor / sql profiler
		-- The tuning advisor helps to get the performance report that is generated by SQL Profiler and provides the appropriate indexing
	-- when setting a primary key for a table ( clustered generate automatically )?

	-- for create a clustered index
	@
		create table tableName
		(
			id int not null,
			name nvarchar(20)
		)
	
		alter table tableName	
		add constraint testPK primary key (id)		-- automatically a clstered index generated
		
		-- if I want to create nonclustered index 
		create nonclustered index indexName on test (name) -- manually create a clustered index on name column

		-- any unique item have a unique nonclustered index
		alter table test
		add constraint consName unique (name)		-- it will generate a unique non clustered index to the name
	@

	-- clustered index and unique non clustered are added automatically or manually create by addding constraing [ primary key / unique ]
	-- non clustered index manually create

	-- to cluster any other column not primary key column
		-- creating the table without primary key 
		-- create cluster index on nameColumn
		-- then now we could make the primary key
			-- here the order ordered by the cluster not the primary key because the primary key is not clustered 
				-- after setting the primary key it will automatically try to make it cluster index but will find out then that another column took the cluster index so it won't become clustered
	--[ non unique / unique / non clustered / clustered / primary key ] mix all of them
	
-- Normalizzation process of decomposing bad relations and composing them into small relations
 
-- search for denormalization?
	-- functinal dependency
		-- name id all data of a record is social security number ( functioning depend on primary key )
	-- Normalization forms [ from first to third normal form ] is important

	migration?
	when to choose stored procedure not functions 
		returns what tables values strings or what

	all in erd
	all in mapping
	division takes place after that
	functionalitis
	indexex 
	functions
	stored procedures
	triggers
	transactions [ rollback / commit ]
	
	count ten days after sunday

	erd must take three days at maximum all the project depent on that steps
	the difficult thing in that projecct that I don't have an interface that talk with me in the project like testing 

	intake : 37 system development Assuit
	no dummy data => you have to record real data $$$
	we have to prepare test cases before project dicussion
	
	data to store questions to put in the database and test data
	and prepare
